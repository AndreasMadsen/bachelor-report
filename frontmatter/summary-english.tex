%!TEX root = ../Thesis.tex
\chapter{Summary (English)}

This thesis investigates modern ways to construct a latent representation of documents. Two out of the three models takes the word ordering into account. Because of this they go beyond the old bag-of-word strategy which can't capture the semantic meaning embedded in the word ordering. 

The intended application is to be able to cluster documents such that each cluster contains news articles about a single story. This is a much more sensitive clustering problem than topic modelling which is a somewhat solved problem. It is because of this sensitivity that taking the word order into account is important.

The first two models are conceptually very simple, but has been shown to be very effective in understanding the semantic meaning of words \cite{word2vec-details, doc2vec}. The last model is much more advanced and is based on a recent paper which have used a recurrent neural network to translate from English to French \cite{sutskever}. In this thesis the model is adapted to find latent representations for news articles.

These methods have many applications, in general finding latent representation of documents is a well known topic. The methods could for example extend to other data sources, such as patient diagnostics or drafts for legal acts.
Once the stories have been clustered, more detailed question can be asked and analyzed. Such as which countries that show interest in a particular story, what kind of political perspective exists and does the amount of attention change over time.
